{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748d17db-3148-4c28-b740-5feaff2164e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\apps\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 26 features, but MinMaxScaler is expecting 25 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m denorm_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(denorm, columns\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# === 8. Re-normalize for Detection Model ===\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m scaled_for_detection \u001b[38;5;241m=\u001b[39m \u001b[43mdetection_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m scaled_for_detection \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(scaled_for_detection, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# === 9. Anomaly Detection ===\u001b[39;00m\n",
      "File \u001b[1;32mE:\\apps\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mE:\\apps\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:532\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    528\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    530\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 532\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    543\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32mE:\\apps\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mE:\\apps\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 26 features, but MinMaxScaler is expecting 25 features as input."
     ]
    }
   ],
   "source": [
    "# === 0. Imports ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# === 1. Load Models ===\n",
    "forecast_model = tf.keras.models.load_model(\"best_lstm_seq2seq_forecaster.h5\")\n",
    "detection_model = tf.keras.models.load_model(\"best_transformer_autoencoder.h5\")\n",
    "\n",
    "# === 2. Load Scalers ===\n",
    "forecast_scaler = joblib.load(\"forecast_scaler.pkl\")\n",
    "detection_scaler = joblib.load(\"detection_scaler.pkl\")\n",
    "\n",
    "# === 3. Load Input CSV ===\n",
    "file_path = \"../../data/test_sequences/sequence_1_len10.csv\"  # <-- your input file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "if 'DateTime' in df.columns:\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df.set_index('DateTime', inplace=True)\n",
    "\n",
    "if 'labels' in df.columns:\n",
    "    df = df.drop(columns=['labels'])\n",
    "\n",
    "# === 4. Normalize Input for Forecast Model ===\n",
    "scaled_forecast = forecast_scaler.transform(df.values)\n",
    "df_scaled_forecast = pd.DataFrame(scaled_forecast, index=df.index, columns=df.columns)y\n",
    "\n",
    "# === 5. Create Input Sequence ===\n",
    "INPUT_STEPS = 10\n",
    "FORECAST_STEPS = 10\n",
    "\n",
    "input_seq = df_scaled_forecast.values[-INPUT_STEPS:]  # last 10\n",
    "input_seq = np.expand_dims(input_seq, axis=0)\n",
    "\n",
    "# === 6. Forecast ===\n",
    "y_pred = forecast_model.predict(input_seq)\n",
    "\n",
    "# === 7. De-normalize Forecast to Real World ===\n",
    "y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[2])\n",
    "denorm = forecast_scaler.inverse_transform(y_pred_reshaped)\n",
    "denorm_df = pd.DataFrame(denorm, columns=df.columns)\n",
    "\n",
    "# === 8. Re-normalize for Detection Model ===\n",
    "scaled_for_detection = detection_scaler.transform(denorm)\n",
    "scaled_for_detection = np.expand_dims(scaled_for_detection, axis=0)\n",
    "\n",
    "# === 9. Anomaly Detection ===\n",
    "reconstructed = detection_model.predict(scaled_for_detection)\n",
    "reconstruction_errors = np.mean((scaled_for_detection - reconstructed) ** 2, axis=(1, 2))\n",
    "\n",
    "# === 10. Thresholding ===\n",
    "MANUAL_PERCENTILE = 90\n",
    "threshold = np.percentile(reconstruction_errors, MANUAL_PERCENTILE)\n",
    "anomaly_flag = int(reconstruction_errors[0] > threshold)\n",
    "\n",
    "# === 11. Add Timestamps ===\n",
    "time_step_minutes = int((df.index[1] - df.index[0]).total_seconds() // 60)\n",
    "start_time = df.index[-1] + pd.Timedelta(minutes=time_step_minutes)\n",
    "timestamps = [start_time + pd.Timedelta(minutes=i * time_step_minutes) for i in range(FORECAST_STEPS)]\n",
    "denorm_df.insert(0, \"DateTime\", timestamps)\n",
    "\n",
    "# === 12. Display Results ===\n",
    "print(\"üìà Forecasted Values:\")\n",
    "display(denorm_df)\n",
    "\n",
    "print(f\"üîç Reconstruction Error: {reconstruction_errors[0]:.6f}\")\n",
    "print(f\"üö® Anomaly Detected: {'Yes' if anomaly_flag else 'No'} (Threshold: {threshold:.6f})\")\n",
    "\n",
    "# === 13. Optional Plot ===\n",
    "plt.figure(figsize=(14, 5))\n",
    "for col in df.columns[:3]:  # first 3 variables\n",
    "    plt.plot(denorm_df['DateTime'], denorm_df[col], label=col)\n",
    "plt.title(\"Forecasted Sequence\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24020800-cb8c-4d52-bb59-efe3275af206",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
